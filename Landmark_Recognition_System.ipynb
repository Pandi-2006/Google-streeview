{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Suppress TensorFlow warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "# --- 0. GOOGLE COLAB SETUP & PATHS (CRITICAL) ---\n",
        "\n",
        "# Set the path to the Colab content directory\n",
        "DATA_PATH = '/content'\n",
        "CSV_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
        "IMG_DIR = os.path.join(DATA_PATH, 'train/')\n",
        "\n",
        "print(\"--- Colab Setup: Data Upload Instructions ---\")\n",
        "\n",
        "print(\"\\n!!! CRITICAL ACTION REQUIRED: UPLOAD DATA !!!\")\n",
        "print(\"To run this successfully, you must manually upload the following files:\")\n",
        "print(\"1. **Upload `train.csv`**: Upload the file directly to the `/content` folder using the Colab file panel (left sidebar).\")\n",
        "print(\"2. **Upload Images**: Create a subfolder named `train` inside `/content` and upload a very small subset (around 100MB) of images into it. You MUST preserve the original nested subfolder structure (e.g., /content/train/0/0/0/...) for the image paths to work.\")\n",
        "print(\"--------------------------------------------------------------------------\")\n",
        "\n",
        "# 1. Check for CSV file existence. This is the absolute requirement to proceed.\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    print(f\"\\n--- CRITICAL ERROR: FILE NOT FOUND ---\")\n",
        "    print(f\"File: {CSV_PATH}\")\n",
        "    print(f\"Action: Please ensure 'train.csv' has been successfully uploaded to the '/content' directory.\")\n",
        "    sys.exit(1)\n",
        "else:\n",
        "    print(f\"\\nFile {os.path.basename(CSV_PATH)} found. Proceeding with data loading and filtering.\")\n",
        "\n",
        "# 2. Ensure the image directory exists\n",
        "if not os.path.exists(IMG_DIR):\n",
        "    os.makedirs(IMG_DIR)\n",
        "\n",
        "print(\"\\n--- Setup Check Complete ---\")\n",
        "\n",
        "# --- 1. GLOBAL CONFIGURATION ---\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "IMG_SIZE = 128  # Consistent image size for training\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "WEIGHT_DECAY = 0.0001\n",
        "DROPOUT_RATE = 0.5\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# --- MINIMUM DATASET SETTINGS (FOR MINIMAL DATA/MEMORY USE) ---\n",
        "# This filter ensures the memory footprint is minimal and training is fast.\n",
        "MIN_IMAGES_PER_CLASS = 10  # Only include landmarks with at least 10 images\n",
        "MAX_CLASSES = 5            # Limit to the top 5 most frequent, suitable classes\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "# --- 2. CUSTOM DATA GENERATOR (Memory Efficient) ---\n",
        "\n",
        "class LandmarkDataGenerator(Sequence):\n",
        "    \"\"\"\n",
        "    Keras Sequence object to efficiently generate batches of images from disk.\n",
        "    Crucial for large datasets as it avoids loading all images into memory.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, img_size, batch_size, class_list, augmentation=None, shuffle=True):\n",
        "        self.df = df\n",
        "        self.img_size = img_size\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentation = augmentation\n",
        "        self.shuffle = shuffle\n",
        "        self.class_list = class_list\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of batches per epoch\n",
        "        return int(np.floor(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Updates indexes after each epoch\n",
        "        self.indexes = np.arange(len(self.df))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def img_read_resize(self, img_path):\n",
        "        \"\"\"Reads, resizes, and converts image to RGB format.\"\"\"\n",
        "        try:\n",
        "            img = cv2.imread(img_path)\n",
        "            # If the image is not found (due to incomplete subset upload), return a black image\n",
        "            if img is None:\n",
        "                return np.zeros((self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img_redim = cv2.resize(img_rgb, (self.img_size, self.img_size))\n",
        "            return img_redim.astype(np.float32) / 255.0 # Normalize immediately\n",
        "        except Exception:\n",
        "            # Handle general processing errors by returning a black image\n",
        "            return np.zeros((self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Generate one batch of data\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_df = self.df.iloc[indexes]\n",
        "\n",
        "        X_batch = np.empty((self.batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "        y_batch = np.empty((self.batch_size), dtype=np.int32)\n",
        "\n",
        "        for i, row in enumerate(batch_df.itertuples()):\n",
        "            # Load and preprocess image\n",
        "            X_batch[i,] = self.img_read_resize(row.img_path)\n",
        "            y_batch[i] = row.class_idx\n",
        "\n",
        "        # Apply augmentation only to training data\n",
        "        if self.augmentation and len(X_batch) > 0:\n",
        "             # Augmentation expects a TensorFlow tensor/dataset, so we wrap it\n",
        "             X_batch = self.augmentation(X_batch)\n",
        "\n",
        "        return X_batch, y_batch\n",
        "\n",
        "\n",
        "# --- 3. DATA LOADING & PREPROCESSING (DataFrame only) ---\n",
        "\n",
        "def load_traindf(csv_path, img_dir):\n",
        "    \"\"\"\n",
        "    Loads the training dataframe and applies the strict size filtering.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        traindf = pd.read_csv(csv_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\nFATAL ERROR: CSV not found at {csv_path}. Did you upload it?\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    traindf['landmark_id'] = traindf['landmark_id'].apply(np.int32)\n",
        "\n",
        "    # 1. Filter 1: Remove rare classes\n",
        "    counts = traindf['landmark_id'].value_counts()\n",
        "    frequent_landmarks = counts[counts >= MIN_IMAGES_PER_CLASS].index\n",
        "    traindf = traindf[traindf['landmark_id'].isin(frequent_landmarks)]\n",
        "\n",
        "    # 2. Filter 2: Select only the top MAX_CLASSES\n",
        "    if len(frequent_landmarks) > MAX_CLASSES:\n",
        "        top_landmarks = traindf['landmark_id'].value_counts().nlargest(MAX_CLASSES).index\n",
        "        traindf = traindf[traindf['landmark_id'].isin(top_landmarks)]\n",
        "\n",
        "    traindf = traindf.reset_index(drop=True)\n",
        "\n",
        "    # 3. Construct the full image path\n",
        "    traindf['img_path'] = traindf['id'].apply(\n",
        "        lambda x: os.path.join(img_dir, x[0], x[1], x[2], x + '.jpg')\n",
        "    )\n",
        "\n",
        "    # 4. Map class IDs to sequential integers (0, 1, 2...)\n",
        "    class_list = sorted(traindf['landmark_id'].unique().tolist())\n",
        "    class_to_idx = {cls: idx for idx, cls in enumerate(class_list)}\n",
        "    traindf['class_idx'] = traindf['landmark_id'].map(class_to_idx)\n",
        "\n",
        "    print(f\"--- Dataset Filtering Applied ---\")\n",
        "    print(f\"Minimum images per class: {MIN_IMAGES_PER_CLASS}\")\n",
        "    print(f\"Maximum classes selected: {MAX_CLASSES}\")\n",
        "    print(f\"Final reduced dataset size: {len(traindf)} images across {len(class_list)} classes.\")\n",
        "    return traindf, class_list\n",
        "\n",
        "\n",
        "print(\"--- Starting Data Loading & Filtering ---\")\n",
        "traindf, class_list = load_traindf(CSV_PATH, IMG_DIR)\n",
        "M_CLASS = len(class_list)\n",
        "\n",
        "# --- 4. DATA SPLITTING & GENERATOR SETUP ---\n",
        "\n",
        "# Split the dataframe itself (no images loaded yet)\n",
        "train_df, test_df = train_test_split(\n",
        "    traindf, test_size=0.10, random_state=SEED, shuffle=True, stratify=traindf['class_idx']\n",
        ")\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df, test_size=0.1/0.9, random_state=SEED, shuffle=True, stratify=train_df['class_idx']\n",
        ")\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"\\n--- Data Split Summary (DataFrames) ---\")\n",
        "print(f\"Training Samples: {len(train_df)}\")\n",
        "print(f\"Validation Samples: {len(val_df)}\")\n",
        "print(f\"Testing Samples: {len(test_df)}\")\n",
        "\n",
        "\n",
        "# --- 5. DATA AUGMENTATION & GENERATOR INSTANTIATION ---\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\", seed=SEED),\n",
        "    layers.RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2), seed=SEED),\n",
        "    layers.RandomTranslation(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1), seed=SEED),\n",
        "    layers.RandomRotation(factor=(-0.1, 0.1), seed=SEED),\n",
        "    layers.RandomContrast(0.4, seed=SEED),\n",
        "    layers.RandomCrop(IMG_SIZE, IMG_SIZE, seed=SEED)\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "# Create Generators\n",
        "train_generator = LandmarkDataGenerator(\n",
        "    train_df, IMG_SIZE, BATCH_SIZE, class_list,\n",
        "    augmentation=data_augmentation, shuffle=True\n",
        ")\n",
        "val_generator = LandmarkDataGenerator(\n",
        "    val_df, IMG_SIZE, BATCH_SIZE, class_list,\n",
        "    augmentation=None, shuffle=False\n",
        ")\n",
        "test_generator = LandmarkDataGenerator(\n",
        "    test_df, IMG_SIZE, BATCH_SIZE, class_list,\n",
        "    augmentation=None, shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "# --- 6. MODEL DEFINITION (TRANSFER LEARNING) ---\n",
        "\n",
        "print(\"\\n--- Defining Model: ResNet50V2 with Custom Head ---\")\n",
        "\n",
        "base_model = ResNet50V2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        ")\n",
        "\n",
        "base_model.trainable = False # Start by freezing the base\n",
        "\n",
        "model_head = tf.keras.Sequential([\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(\n",
        "        512,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=regularizers.l2(WEIGHT_DECAY)\n",
        "    ),\n",
        "    layers.Dropout(rate=DROPOUT_RATE, seed=SEED),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(M_CLASS, activation='softmax')\n",
        "])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    model_head\n",
        "], name=\"Landmark_Recognizer_ResNet50V2\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# --- 7. OPTIMIZER, COMPILATION, AND CALLBACKS ---\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=3, min_delta=0.0001, verbose=1, min_lr=1e-7)\n",
        "# FIX: Changed filepath to end in .weights.h5 as required by save_weights_only=True\n",
        "checkpoint = ModelCheckpoint('best-weights.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "callbacks_list = [early_stopping, reduce_lr, checkpoint]\n",
        "\n",
        "\n",
        "# --- 8. TRAINING ---\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "train_start_time = time.time()\n",
        "\n",
        "# Training using the memory-efficient generators\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "train_end_time = time.time()\n",
        "training_duration = (train_end_time - train_start_time) / 60\n",
        "print(f\"\\nTraining duration: {training_duration:.2f} minutes\")\n",
        "\n",
        "# --- 9. EVALUATION & RESULTS ---\n",
        "\n",
        "# Load the best weights\n",
        "if os.path.exists('best-weights.weights.h5'):\n",
        "    model.load_weights('best-weights.weights.h5')\n",
        "else:\n",
        "    print(\"Warning: Checkpoint file not found. Using final epoch weights.\")\n",
        "\n",
        "print(\"\\n--- Model Evaluation with Testing Data ---\")\n",
        "loss, accuracy = model.evaluate(test_generator, verbose=1)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# 9.1. Plotting Performance\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss vs. Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['sparse_categorical_accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_sparse_categorical_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy vs. Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 9.2. Classification Report (Precision, Recall, F1-Score)\n",
        "# Get predictions from the test generator\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Extract true labels from the generator\n",
        "y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))])\n",
        "\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "report_classes = [str(cls) for cls in class_list]\n",
        "print(classification_report(y_true, y_pred, target_names=report_classes, zero_division=0))\n",
        "\n",
        "# 9.3. Visual Results (Showing sample predictions)\n",
        "def plot_predictions(generator, model, num_samples=9):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    # Get one batch from the generator\n",
        "    if len(generator) == 0:\n",
        "        print(\"Cannot plot predictions: Test generator is empty.\")\n",
        "        return\n",
        "\n",
        "    X_batch, y_true_batch = generator[np.random.randint(0, len(generator))]\n",
        "\n",
        "    # Predict on the batch\n",
        "    y_pred_probs = model.predict(X_batch, verbose=0)\n",
        "    y_pred_batch = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    for i in range(min(num_samples, len(X_batch))):\n",
        "\n",
        "        true_label_idx = y_true_batch[i]\n",
        "        predicted_label_idx = y_pred_batch[i]\n",
        "\n",
        "        # Ensure indices are within bounds of class_list\n",
        "        if true_label_idx < len(class_list) and predicted_label_idx < len(class_list):\n",
        "            true_id = class_list[true_label_idx]\n",
        "            predicted_id = class_list[predicted_label_idx]\n",
        "        else:\n",
        "            true_id = \"N/A\"\n",
        "            predicted_id = \"N/A\"\n",
        "\n",
        "        color = 'green' if true_id == predicted_id else 'red'\n",
        "\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        # Denormalize image for display\n",
        "        plt.imshow((X_batch[i] * 255).astype(np.uint8))\n",
        "        plt.title(f'True ID: {true_id}\\nPred ID: {predicted_id}', color=color, fontsize=10)\n",
        "        plt.xticks([]); plt.yticks([])\n",
        "\n",
        "    plt.suptitle('Sample Predictions on Test Data', fontsize=18, y=0.92)\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n--- Visualizing Sample Predictions ---\")\n",
        "plot_predictions(test_generator, model, num_samples=9)\n",
        "\n",
        "print(\"\\nProject execution finished successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "ase8keZHx6KA",
        "outputId": "83e2068a-6d51-4251-96a6-287c0b99e9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Colab Setup: Data Upload Instructions ---\n",
            "\n",
            "!!! CRITICAL ACTION REQUIRED: UPLOAD DATA !!!\n",
            "To run this successfully, you must manually upload the following files:\n",
            "1. **Upload `train.csv`**: Upload the file directly to the `/content` folder using the Colab file panel (left sidebar).\n",
            "2. **Upload Images**: Create a subfolder named `train` inside `/content` and upload a very small subset (around 100MB) of images into it. You MUST preserve the original nested subfolder structure (e.g., /content/train/0/0/0/...) for the image paths to work.\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            "File train.csv found. Proceeding with data loading and filtering.\n",
            "\n",
            "--- Setup Check Complete ---\n",
            "--- Starting Data Loading & Filtering ---\n",
            "--- Dataset Filtering Applied ---\n",
            "Minimum images per class: 10\n",
            "Maximum classes selected: 5\n",
            "Final reduced dataset size: 13137 images across 5 classes.\n",
            "\n",
            "--- Data Split Summary (DataFrames) ---\n",
            "Training Samples: 10509\n",
            "Validation Samples: 1314\n",
            "Testing Samples: 1314\n",
            "\n",
            "--- Defining Model: ResNet50V2 with Custom Head ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Landmark_Recognizer_ResNet50V2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Landmark_Recognizer_ResNet50V2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_2 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │    \u001b[38;5;34m16,782,341\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,782,341</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,347,141\u001b[0m (153.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,347,141</span> (153.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,781,317\u001b[0m (64.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,317</span> (64.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,565,824\u001b[0m (89.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,565,824</span> (89.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Model Training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m 85/328\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:29\u001b[0m 2s/step - loss: 1.9220 - sparse_categorical_accuracy: 0.2067"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}